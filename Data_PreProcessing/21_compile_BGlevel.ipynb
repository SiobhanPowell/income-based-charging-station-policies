{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee915ae",
   "metadata": {},
   "source": [
    "This file compiles the BG-level dataset, used for the analysis of the neighborhood effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import us\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import category_groupings_250403 as cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37211b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ''\n",
    "path = root + 'Data/'\n",
    "path_US_data = root + 'Data/geodata/'\n",
    "result_path = root + 'final_data/'\n",
    "path_IRA = root + 'Data/IRA/1.0-shapefile-codebook/usa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0033aa1",
   "metadata": {},
   "source": [
    "# Compile state-specific BG-level datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which states to compile\n",
    "states = []\n",
    "for state in us.states.STATES:\n",
    "    states +=[state.abbr]\n",
    "states += ['DC']\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f223ee9",
   "metadata": {},
   "source": [
    "## Load socioeconomics on BG-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93878822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect\n",
    "df_socioecon = pd.read_csv(result_path + 'BGlevel/level_BG.csv')\n",
    "df_socioecon['STATEFP'] = df_socioecon['STATEFP'].astype(str).str.zfill(2)\n",
    "df_socioecon['COUNTYFP'] = df_socioecon['COUNTYFP'].astype(str).str.zfill(5)\n",
    "df_socioecon['BGFP'] = df_socioecon['BGFP'].astype(str).str.zfill(12)\n",
    "df_socioecon.set_index('BGFP', inplace=True)\n",
    "df_socioecon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split socioeconomic data by state\n",
    "for state in tqdm(states):\n",
    "    if state == 'DC':\n",
    "        fips = '11'\n",
    "    else:\n",
    "        fips = us.states.lookup(state).fips\n",
    "\n",
    "    # Filter for stations in state\n",
    "    df_socioecon_state = df_socioecon.loc[df_socioecon['STATEFP'] == fips]\n",
    "    # df_socioecon_state.reset_index(inplace=True)\n",
    "\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f21c18",
   "metadata": {},
   "source": [
    "## Add nb income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column duplicates which we will not merge on\n",
    "cols_dup = ['median_household_income_byBG','total_pop_byBG','STATEFP','COUNTYFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ac4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nb income\n",
    "for state in tqdm(states):\n",
    "    if state == 'DC':\n",
    "        fips = '11'\n",
    "    else:\n",
    "        fips = us.states.lookup(state).fips\n",
    "    # Read current socioecon file\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')\n",
    "    df_socioecon_state['STATEFP'] = df_socioecon_state['STATEFP'].astype(str).str.zfill(2)\n",
    "    df_socioecon_state['COUNTYFP'] = df_socioecon_state['COUNTYFP'].astype(str).str.zfill(5)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    df_socioecon_state.set_index('BGFP', inplace=True)\n",
    "    # Read nb income\n",
    "    df_nbincome_state = pd.read_csv(result_path + 'BGlevel/level_BG_'+state+'_wnbincome.csv')\n",
    "    df_nbincome_state['BGFP'] = df_nbincome_state['BGFP'].astype(str).str.zfill(12)\n",
    "    df_nbincome_state.set_index('BGFP', inplace=True)\n",
    "    # Drop duplicated columns\n",
    "    for col_del in cols_dup:\n",
    "        df_nbincome_state.drop(col_del,axis=1,inplace=True)\n",
    "    # Merge   \n",
    "    df_socioecon_state = df_socioecon_state.merge(df_nbincome_state, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # Save data\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100d842",
   "metadata": {},
   "source": [
    "## Add Res Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "for state in tqdm(states):\n",
    "    if state == 'DC':\n",
    "        fips = '11'\n",
    "    else:\n",
    "        fips = us.states.lookup(state).fips\n",
    "    # Read current socioecon file\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')\n",
    "    df_socioecon_state['STATEFP'] = df_socioecon_state['STATEFP'].astype(str).str.zfill(2)\n",
    "    df_socioecon_state['COUNTYFP'] = df_socioecon_state['COUNTYFP'].astype(str).str.zfill(5)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    df_socioecon_state.set_index('BGFP', inplace=True)\n",
    "    # Rename\n",
    "    df_socioecon_state.rename(columns={'ResCars_pp_BG_byBG':'total_ResCars_byBG'}, inplace=True)    \n",
    "    # Save data\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95099ec0",
   "metadata": {},
   "source": [
    "## Add county-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00085bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read counry-level data\n",
    "gdf_county = pd.read_csv(result_path + 'level_county.csv',index_col=0)\n",
    "gdf_county['COUNTYFP'] = gdf_county['COUNTYFP'].astype(str).str.zfill(5)\n",
    "gdf_county.drop('STATEFP', axis=1, inplace=True) # to avoid double columns\n",
    "gdf_county.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b832420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge county data and stations\n",
    "for state in tqdm(states):\n",
    "    # Read stations\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['STATEFP'] = df_socioecon_state['STATEFP'].astype(str).str.zfill(2)\n",
    "    df_socioecon_state['COUNTYFP'] = df_socioecon_state['COUNTYFP'].astype(str).str.zfill(5)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Merge\n",
    "    df_socioecon_state = df_socioecon_state.merge(gdf_county, how='left', left_on='COUNTYFP', right_on='COUNTYFP')\n",
    "    df_socioecon_state.set_index('BGFP', inplace=True)\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd673d",
   "metadata": {},
   "source": [
    "## Add state-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc28c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add state-level info\n",
    "df_state_level = pd.read_csv(result_path + 'level_state.csv')\n",
    "df_state_level['STATEFP'] = df_state_level['STATEFP'].astype(str).str.zfill(2)\n",
    "df_state_level.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge county data and stations\n",
    "for state in tqdm(states):\n",
    "    # Read stations\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['STATEFP'] = df_socioecon_state['STATEFP'].astype(str).str.zfill(2)\n",
    "    df_socioecon_state['COUNTYFP'] = df_socioecon_state['COUNTYFP'].astype(str).str.zfill(5)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Merge\n",
    "    df_socioecon_state = df_socioecon_state.merge(df_state_level, how='left', on='STATEFP')\n",
    "    df_socioecon_state.set_index('BGFP', inplace=True)\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481b42f",
   "metadata": {},
   "source": [
    "## Nearest highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add highways\n",
    "gdf_hwy_state = pd.read_csv(result_path + 'BGlevel/level_bg_'+state +'_hwy.csv',index_col=0)\n",
    "gdf_hwy_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5287e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hwys and stations\n",
    "for state in tqdm(states):\n",
    "    # Read stations\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Read hwy distance\n",
    "    gdf_hwy_state = pd.read_csv(result_path + 'BGlevel/level_bg_'+state +'_hwy.csv',index_col=0)\n",
    "    gdf_hwy_state['BGFIPS'] = gdf_hwy_state['BGFIPS'].astype(int).astype(str).str.zfill(12)\n",
    "    gdf_hwy_state.rename(columns={'BGFIPS':'BGFP'},inplace=True)\n",
    "    # Merge\n",
    "    df_socioecon_state = df_socioecon_state.merge(gdf_hwy_state, how='left', on=['BGFP'])\n",
    "    df_socioecon_state.set_index('BGFP',inplace=True)\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174a771",
   "metadata": {},
   "source": [
    "## Add number of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read original stations wFIPS\n",
    "df_stations = pd.read_csv(result_path + '00_alt_fuel_stations (Apr 3 2023)_wFIPS.csv',index_col=0) # ,dtype={'STATEFP':int,'COUNTYFP':int,'BGFP':int})\n",
    "df_stations = df_stations.loc[~df_stations['BGFP'].isna()]\n",
    "df_stations['STATEFP'] = df_stations['STATEFP'].astype(str).str.zfill(2)\n",
    "df_stations['COUNTYFP'] = df_stations['COUNTYFP'].astype(str).str.zfill(5)\n",
    "df_stations['BGFP'] = df_stations['BGFP'].astype(int).astype(str).str.zfill(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 largest charging networks\n",
    "list_networks = df_stations.groupby('EV Network').size().sort_values(ascending=False).index.tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272803e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge BG and no of stations\n",
    "for state in tqdm(states):\n",
    "    # Read stations\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Filter stations\n",
    "    df_stations_state = df_stations.loc[df_stations['State'] == state]\n",
    "    # All stations (public and private)\n",
    "    s = df_stations_state.groupby('BGFP').size()\n",
    "    df = pd.DataFrame(index=s.index,columns=['no_stations_all'],data=s.values)\n",
    "    if 'no_stations_all' in df_socioecon_state.columns.to_list():\n",
    "        df_socioecon_state.drop('no_stations_all',axis=1,inplace=True)\n",
    "    df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "    df_socioecon_state['no_stations_all'] = df_socioecon_state['no_stations_all'].fillna(0)\n",
    "    # Keep name to avoid conflicts later\n",
    "    df_socioecon_state['no_stations'] = df_socioecon_state['no_stations_all']\n",
    "    if True:\n",
    "        # All private stations (for robustness)\n",
    "        df_stations_state_private = df_stations_state.loc[df_stations_state['Access Code'] != 'public']\n",
    "        s = df_stations_state_private.groupby('BGFP').size()\n",
    "        df = pd.DataFrame(index=s.index,columns=['no_stations_privateonly'],data=s.values)\n",
    "        if 'no_stations_privateonly' in df_socioecon_state.columns.to_list():\n",
    "            df_socioecon_state.drop('no_stations_privateonly',axis=1,inplace=True)\n",
    "        df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "        df_socioecon_state['no_stations_privateonly'] = df_socioecon_state['no_stations_privateonly'].fillna(0)\n",
    "        # All public stations\n",
    "        df_stations_state_public = df_stations_state.loc[df_stations_state['Access Code'] != 'private']\n",
    "        s = df_stations_state_public.groupby('BGFP').size()\n",
    "        df = pd.DataFrame(index=s.index,columns=['no_stations_publiconly'],data=s.values)\n",
    "        if 'no_stations_publiconly' in df_socioecon_state.columns.to_list():\n",
    "            df_socioecon_state.drop('no_stations_publiconly',axis=1,inplace=True)\n",
    "        df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "        df_socioecon_state['no_stations_publiconly'] = df_socioecon_state['no_stations_publiconly'].fillna(0)\n",
    "        # L2 (based on all private + public stations)\n",
    "        df_stations_state_L2 = df_stations_state[df_stations_state['EV DC Fast Count'].isna()]\n",
    "        s = df_stations_state_L2.groupby('BGFP').size()\n",
    "        df = pd.DataFrame(index=s.index,columns=['no_L2_stations'],data=s.values)\n",
    "        if 'no_L2_stations' in df_socioecon_state.columns.to_list():\n",
    "            df_socioecon_state.drop('no_L2_stations',axis=1,inplace=True)\n",
    "        df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "        df_socioecon_state['no_L2_stations'] = df_socioecon_state['no_L2_stations'].fillna(0)\n",
    "        # DC (based on all private + public stations)\n",
    "        df_stations_state_DC = df_stations_state[~df_stations_state['EV DC Fast Count'].isna()]\n",
    "        s = df_stations_state_DC.groupby('BGFP').size()\n",
    "        df = pd.DataFrame(index=s.index,columns=['no_DC_stations'],data=s.values)\n",
    "        if 'no_DC_stations' in df_socioecon_state.columns.to_list():\n",
    "            df_socioecon_state.drop('no_DC_stations',axis=1,inplace=True)\n",
    "        df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "        df_socioecon_state['no_DC_stations'] = df_socioecon_state['no_DC_stations'].fillna(0)\n",
    "        # Networks (based on all private + public stations)\n",
    "        for network in list_networks:\n",
    "            # All stations\n",
    "            df_stations_state_network = df_stations_state.loc[df_stations_state['EV Network'] == network]\n",
    "            col_network = 'no_stations_' + network.replace(' ','_')\n",
    "            s = df_stations_state_network.groupby('BGFP').size()\n",
    "            df = pd.DataFrame(index=s.index,columns=[col_network],data=s.values)\n",
    "            if col_network in df_socioecon_state.columns.to_list():\n",
    "                df_socioecon_state.drop(col_network,axis=1,inplace=True)\n",
    "            df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "            df_socioecon_state[col_network] = df_socioecon_state[col_network].fillna(0)\n",
    "        # Merge\n",
    "        df_socioecon_state.set_index('BGFP',inplace=True)\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f47123",
   "metadata": {},
   "source": [
    "## Add no PoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea524014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all categories\n",
    "top_cats_edited = []\n",
    "for key in cg.category_grouping('key', return_key_list=True):\n",
    "    top_cats_edited += [cg.category_grouping(key)]\n",
    "top_cats_edited = sorted(set(top_cats_edited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616cedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge BG and no of PoI\n",
    "for state in tqdm(states):\n",
    "    # Read BGs\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Read PoI\n",
    "    df_dewey_state = pd.read_csv(result_path + 'Dewey/01_compiled_'+state+'.csv',index_col=0)\n",
    "    df_dewey_state = df_dewey_state.loc[~df_dewey_state['BGFP'].isna()]\n",
    "    df_dewey_state['BGFP'] = df_dewey_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # All BGs\n",
    "    s = df_dewey_state.groupby('BGFP').size()\n",
    "    df = pd.DataFrame(index=s.index,columns=['no_PoI'],data=s.values)\n",
    "    df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "    df_socioecon_state['no_PoI'] = df_socioecon_state['no_PoI'].fillna(0)\n",
    "    if True:\n",
    "        # Assign edited top categories\n",
    "        df_dewey_state['top_category_edit'] = None\n",
    "        all_top_cats = cg.category_grouping('key', return_key_list=True)\n",
    "        for key in all_top_cats:\n",
    "            df_dewey_state.loc[df_dewey_state['top_category'] == key, 'top_category_edit'] = cg.category_grouping(key)\n",
    "        # Top categories\n",
    "        for top_cat in top_cats_edited:\n",
    "            df_dewey_state_topcat = df_dewey_state.loc[df_dewey_state['top_category_edit'] == top_cat]\n",
    "            col_topcat = 'no_PoI_' + top_cat.replace(' ','_')\n",
    "            s = df_dewey_state_topcat.groupby('BGFP').size()\n",
    "            df = pd.DataFrame(index=s.index,columns=[col_topcat],data=s.values)\n",
    "            df_socioecon_state = df_socioecon_state.merge(df,how='left',left_on='BGFP',right_index=True)\n",
    "            df_socioecon_state[col_topcat] = df_socioecon_state[col_topcat].fillna(0)\n",
    "        # Merge\n",
    "        df_socioecon_state.set_index('BGFP',inplace=True)\n",
    "    # Save\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d7485",
   "metadata": {},
   "source": [
    "## Add IRA info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e6c04",
   "metadata": {},
   "source": [
    "### Whether BG is IRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge BG and IRA info\n",
    "for state in tqdm(states):\n",
    "    # Read BGs\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Read IRA\n",
    "    df_IRA = pd.read_csv(result_path + 'BGlevel/level_BG_'+state+'_IRA.csv') # ,index_col=0)\n",
    "    df_IRA['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    df_IRA.drop('BGFIPS', axis=1, inplace=True) # to avoid double columns\n",
    "    # Merge\n",
    "    df_socioecon_state = df_socioecon_state.merge(df_IRA, how='left', on='BGFP')\n",
    "    # Save\n",
    "    df_socioecon_state.set_index('BGFP',inplace=True)\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f80f1",
   "metadata": {},
   "source": [
    "### Whether BG has disadvantaged neighoring BGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB IRA\n",
    "for state in tqdm(states):\n",
    "    # Read BGs\n",
    "    df_socioecon_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv') # ,index_col=0)\n",
    "    df_socioecon_state['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    # Read IRA\n",
    "    df_IRA = pd.read_csv(result_path + 'BGlevel/level_BG_'+state+'_nbIRA.csv',index_col=0)\n",
    "    df_IRA['BGFP'] = df_socioecon_state['BGFP'].astype(int).astype(str).str.zfill(12)\n",
    "    df_IRA.drop('BGFIPS', axis=1, inplace=True) # to avoid double columns\n",
    "    # Merge\n",
    "    df_socioecon_state = df_socioecon_state.merge(df_IRA, how='left', on='BGFP')\n",
    "    # Save\n",
    "    df_socioecon_state.set_index('BGFP',inplace=True)\n",
    "    df_socioecon_state.to_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17f0ae",
   "metadata": {},
   "source": [
    "# Combine all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All states\n",
    "states = []\n",
    "for state in us.states.STATES:\n",
    "    states +=[state.abbr]\n",
    "states += ['DC']\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72634672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to single US-level file\n",
    "df_BG_US = pd.DataFrame()\n",
    "for state in states:\n",
    "    # Read data\n",
    "    df_BG_state = pd.read_csv(result_path + 'BGlevel/21_level_BG_' + state + '_compiled.csv',index_col=0)\n",
    "    # Compile\n",
    "    if state == states[0]:\n",
    "        df_BG_US = df_BG_state.copy()\n",
    "    else:\n",
    "        df_BG_US = pd.concat([df_BG_US, df_BG_state], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc9e74",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "label = '250702'\n",
    "df_BG_US.to_csv(result_path + 'BGlevel/21_level_BG_US_compiled_'+label+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
