{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file reads socioeconomic data, assigns to BGs, and computes distribution measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import geopandas as geopd\n",
    "import us\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import state_name_crs_mappings_ML as crsm\n",
    "from pysal.explore import esda\n",
    "from pysal.lib import weights\n",
    "from inequality.gini import Gini\n",
    "from inequality.gini import Gini_Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ''\n",
    "path = root + 'Data/'\n",
    "path_US_data = root + 'Data/geodata/'\n",
    "result_path = root + 'final_data/'\n",
    "path_IRA = root + 'Data/IRA/1.0-shapefile-codebook/usa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether folder exists, if not create it\n",
    "folder = result_path + 'BGlevel/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Socio-economic data (output of 10_assemble_socioeconomicdata.ipynb)\n",
    "file_socioecon = result_path + 'CENSUS_selected_cols_EV.csv'\n",
    "df_socioecon = pd.read_csv(file_socioecon,index_col=0)\n",
    "df_socioecon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FIPS codes\n",
    "df_socioecon['BGFP'] = df_socioecon.index.astype(str).str.zfill(12)\n",
    "df_socioecon['COUNTYFP'] = df_socioecon['BGFP'].str[:5]\n",
    "df_socioecon['STATEFP'] = df_socioecon['BGFP'].str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign socioeconomics to BGs and compute state-level distribution measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States of interest\n",
    "states = []\n",
    "for state in us.states.STATES:\n",
    "\tstates +=[state.abbr]\n",
    "states += ['DC']\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each state, read official BG shapefile, merge socio-economic data, and save separately\n",
    "for state in (states):\n",
    "\tprint(state)\n",
    "\n",
    "\t# Read BG shapefile\n",
    "\tif state == 'DC':\n",
    "\t\tfips = '11'\n",
    "\telse:\n",
    "\t\tfips = us.states.lookup(state).fips\n",
    "\tfile_bg = path + 'geodata/tl_bg/tl_2020_'+fips+'_bg/tl_2020_'+fips+'_bg.shp'\n",
    "\tgdf_bg = geopd.read_file(file_bg)\n",
    "\tdf_bg = gdf_bg[['GEOID','ALAND','geometry']]\n",
    "\tdf_bg.rename(columns={'GEOID':'BGFIPS','ALAND':'BGALAND'},inplace=True)\n",
    "\n",
    "\t# Merge socio-economic data\n",
    "\tdf_bg = df_bg.merge(df_socioecon,how='left',left_on=['BGFIPS'],right_on=['BGFP'])\n",
    "\tno_NaN = len(df_bg.loc[df_bg['BGFP'].isna()])\n",
    "\tif no_NaN > 0:\n",
    "\t\tprint('Warning: '+str(no_NaN)+' BGs in '+state+' have no socio-economic data')\n",
    "\tdf_bg['PopDensity_byBG'] = df_bg['total_pop_byBG']/df_bg['BGALAND']\n",
    "\n",
    "\t# Compute weighted average of income by countyfp (needed for quantile calculation)\n",
    "\tdf_bg['median_household_income_byCNTY'] = np.nan\n",
    "\tdf_socioecon_noNaN = df_bg.dropna(subset=['median_household_income_byBG','total_pop_byBG'])\n",
    "\tdf_socioecon_noNaN['income_weighted'] = df_socioecon_noNaN['total_pop_byBG'] * df_socioecon_noNaN['median_household_income_byBG']\n",
    "\tfor countyfp in tqdm(df_socioecon_noNaN['COUNTYFP'].unique()):\n",
    "\t\t# Weigh incomeXpopulation in BG by total population in county\n",
    "\t\tdf = df_socioecon_noNaN.loc[df_socioecon_noNaN['COUNTYFP'] == countyfp]\n",
    "\t\tdf['income_weighted'] = df['income_weighted'] / df['total_pop_byBG'].sum()\n",
    "\t\t# Sum up\n",
    "\t\tdf_bg.loc[df_bg['COUNTYFP'] == countyfp, 'median_household_income_byCNTY'] = int(np.round(df['income_weighted'].sum(),0))\n",
    "\n",
    "\t# Compute state-level income quantiles\n",
    "\tdf_bg['income_quantile_county_state'] = np.nan\n",
    "\tdf_bg['income_quantile_bg_state'] = np.nan\n",
    "\tdf_socioecon_noNaNCNTY = df_bg.dropna(subset=['median_household_income_byCNTY'])\n",
    "\tdf_socioecon_noNaNBG = df_bg.dropna(subset=['median_household_income_byBG'])\n",
    "\n",
    "\ti = 1.\n",
    "\tfor qu in np.arange(0.,1.,0.2):\n",
    "\t\t# US county\n",
    "\t\tquantile = np.quantile(df_socioecon_noNaNCNTY['median_household_income_byCNTY'],qu)\n",
    "\t\tdf_bg.loc[(df_bg['median_household_income_byCNTY'] >= quantile), 'income_quantile_county_state'] = i\n",
    "\t\t# BG\n",
    "\t\tquantile = np.quantile(df_socioecon_noNaNBG['median_household_income_byBG'],qu)\n",
    "\t\tdf_bg.loc[(df_bg['median_household_income_byBG'] >= quantile), 'income_quantile_bg_state'] = i\n",
    "\t\ti += 1\n",
    "\n",
    "\t# Include Gini coefficient\n",
    "\tdf_bg['Gini_state'] = Gini(df_bg.loc[~df_bg['median_household_income_byBG'].isna()]['median_household_income_byBG'].values).g\n",
    "\tdf_bg['Gini_county'] = np.nan\n",
    "\tfor county in tqdm(df_bg['COUNTYFP'].unique()):\n",
    "\t\tdf_bg_county = df_bg.loc[df_bg['COUNTYFP']==county]\n",
    "\t\tdf_bg_county = df_bg_county.loc[~df_bg_county['median_household_income_byBG'].isna()]\n",
    "\t\tif len(df_bg_county) > 1:\n",
    "\t\t\tgini_county = Gini(df_bg_county['median_household_income_byBG'].values).g\n",
    "\t\t\tif gini_county != 0:\n",
    "\t\t\t\tdf_bg.loc[df_bg['COUNTYFP']==county, 'Gini_county'] = gini_county\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_bg.loc[df_bg['COUNTYFP']==county, 'Gini_county'] = np.nan # seems to be mistake; Moran fails in this case\n",
    "\n",
    "\t# Include geographical seggregation measure: Moran's I\n",
    "    # Impute NaNs\n",
    "\tdf_bg['median_household_income_imputed'] = df_bg['median_household_income_byBG']\n",
    "\tdf_bg.loc[df_bg['median_household_income_byBG'].isna(),'median_household_income_imputed'] = df_bg['median_household_income_byBG'].mean()\n",
    "\t# Compute spatial weights\n",
    "\twq = weights.Queen.from_dataframe(df_bg, use_index=True) # https://pysal.org/notebooks/lib/libpysal/weights.html\n",
    "\tdf_bg['Moran_state'] = esda.Moran(df_bg[\"median_household_income_imputed\"], w=wq).I # value of Moranâ€™s I: perfectly dispersed: -1; perfectly clustered: 1; random: 0\n",
    "\t# County level\n",
    "\tdf_bg['Moran_county'] = 0.\n",
    "\tfor county in tqdm(df_bg['COUNTYFP'].unique()):\n",
    "\t\tdf_bg_county = df_bg.loc[df_bg['COUNTYFP']==county]\n",
    "\t\tif len(df_bg_county) > 1:\n",
    "\t\t\twq = weights.Queen.from_dataframe(df_bg_county, use_index=True) # https://pysal.org/notebooks/lib/libpysal/weights.html\n",
    "\t\t\ttry:\n",
    "\t\t\t\tmoran_county = esda.Moran(df_bg_county[\"median_household_income_imputed\"], w=wq).I\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmoran_county = np.nan\n",
    "\t\t\tdf_bg.loc[df_bg['COUNTYFP']==county,'Moran_county'] = moran_county\n",
    "\n",
    "\t# Drop columns\n",
    "\tdf_bg.drop(columns=['BGFIPS','geometry'],inplace=True)\n",
    "\n",
    "\t# Save\n",
    "\tfile_bg = result_path + 'BGlevel/level_BG_'+state+'.csv'\n",
    "\tdf_bg.to_csv(file_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "df_bg_US = pd.DataFrame()\n",
    "for state in tqdm(states):\n",
    "    # Read file\n",
    "    file_bg = result_path + 'BGlevel/level_BG_'+state+'.csv'\n",
    "    df_bg = pd.read_csv(file_bg,index_col=0)\n",
    "    # Concatenate\n",
    "    if len(df_bg_US) == 0:\n",
    "        df_bg_US = df_bg.copy()\n",
    "    else:\n",
    "        df_bg_US = pd.concat([df_bg_US,df_bg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index\n",
    "df_bg_US.set_index('BGFP',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute US-level quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County quantiles US\n",
    "df_bg_US['income_quantile_county_US'] = np.nan\n",
    "df_dataset_CNTY = df_bg_US[['COUNTYFP','median_household_income_byCNTY']].copy()\n",
    "\n",
    "# Remove implicit weighting by number of BGs - each county counts once\n",
    "df_dataset_CNTY.drop_duplicates(inplace=True)\n",
    "\n",
    "# Add county-level quantile\n",
    "i = 1.\n",
    "for qu in np.arange(0.,1.,0.2):\n",
    "    print(qu)\n",
    "    county_income_lower = np.quantile(df_dataset_CNTY.loc[~df_dataset_CNTY['median_household_income_byCNTY'].isna()]['median_household_income_byCNTY'],qu)\n",
    "    print(county_income_lower)\n",
    "    df_bg_US.loc[(df_bg_US['median_household_income_byCNTY'] >= county_income_lower),'income_quantile_county_US'] = i\n",
    "    i += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BG quantiles US\n",
    "df_bg_US['income_quantile_bg_US'] = np.nan\n",
    "\n",
    "# Add BG-level quantile\n",
    "i = 1.\n",
    "for qu in np.arange(0.,1.,0.2):\n",
    "    print(qu)\n",
    "    BG_income_lower = np.quantile(df_bg_US.loc[~df_bg_US['median_household_income_byBG'].isna()]['median_household_income_byBG'],qu)\n",
    "    print(BG_income_lower)\n",
    "    df_bg_US.loc[(df_bg_US['median_household_income_byBG'] >= BG_income_lower),'income_quantile_bg_US'] = i\n",
    "    i += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg_US.to_csv(result_path + 'BGlevel/level_BG.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
